{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install plotly\n",
    "# %pip install json\n",
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install sci kit-learn\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import copy\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from transformers import BertModel\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "\n",
    "\n",
    "workspace_dir = os.getcwd()\n",
    "workspace_dir = workspace_dir.replace('/notebooks', '')\n",
    "load_pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')\n",
    "\n",
    "is_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get_grade</td>\n",
       "      <td>معدل من چنده؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>get_grade</td>\n",
       "      <td>معدل من چقدر شده؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get_grade</td>\n",
       "      <td>بگو معدل من چیه؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get_grade</td>\n",
       "      <td>معدل من چطور شده است؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get_grade</td>\n",
       "      <td>معدل من چند درصدی است؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                    text\n",
       "0  get_grade           معدل من چنده؟\n",
       "1  get_grade       معدل من چقدر شده؟\n",
       "2  get_grade        بگو معدل من چیه؟\n",
       "3  get_grade   معدل من چطور شده است؟\n",
       "4  get_grade  معدل من چند درصدی است؟"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_json_path = f'{workspace_dir}/datasets/intents.json'\n",
    "\n",
    "with open(input_json_path, \"r\", encoding='utf8') as f:\n",
    "    json_file = json.load(f)\n",
    "\n",
    "raw_intents = []\n",
    "\n",
    "\n",
    "for key, value_list in json_file.items():\n",
    "    for value in value_list:\n",
    "        raw_intents.append([key, value])\n",
    "\n",
    "data = pd.DataFrame(raw_intents, columns=['label', 'text'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get_grade', 'get_passed_units']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(sorted(data['label'].unique()))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "text": [
          "42",
          "25"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "get_grade",
          "get_passed_units"
         ],
         "y": [
          42,
          25
         ]
        }
       ],
       "layout": {
        "bargap": 0.2,
        "bargroupgap": 0.2,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of label within texts [DATA]"
        },
        "xaxis": {
         "title": {
          "text": "Label"
         }
        },
        "yaxis": {
         "title": {
          "text": "Frequency"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "groupby_label = data.groupby('label')['label'].count()\n",
    "if is_interactive():\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(sorted(groupby_label.index)),\n",
    "        y=groupby_label.tolist(),\n",
    "        text=groupby_label.tolist(),\n",
    "        textposition='auto'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text='Distribution of label within texts [DATA]',\n",
    "        xaxis_title_text='Label',\n",
    "        yaxis_title_text='Frequency',\n",
    "        bargap=0.2,\n",
    "        bargroupgap=0.2)\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 3)\n",
      "(6, 3)\n",
      "(7, 3)\n"
     ]
    }
   ],
   "source": [
    "data['label_id'] = data['label'].apply(lambda t: labels.index(t))\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.1, random_state=1, stratify=data['label'])\n",
    "train, valid = train_test_split(train, test_size=0.1, random_state=1, stratify=train['label'])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "x_train, y_train = train['text'].values.tolist(), train['label_id'].values.tolist()\n",
    "x_valid, y_valid = valid['text'].values.tolist(), valid['label_id'].values.tolist()\n",
    "x_test, y_test = test['text'].values.tolist(), test['label_id'].values.tolist()\n",
    "\n",
    "if is_interactive():\n",
    "    print(train.shape)\n",
    "    print(valid.shape)\n",
    "    print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if is_interactive():\n",
    "    print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general config\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 16\n",
    "\n",
    "EPOCHS = 3\n",
    "EEVERY_EPOCH = 1000\n",
    "LEARNING_RATE = 2e-5\n",
    "CLIP = 0.0\n",
    "\n",
    "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
    "OUTPUT_PATH = f'{workspace_dir}/models/intent_classification.bin'\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'get_grade': 0, 'get_passed_units': 1}\n",
      "id2label: {0: 'get_grade', 1: 'get_passed_units'}\n"
     ]
    }
   ],
   "source": [
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "if is_interactive():\n",
    "    print(f'label2id: {label2id}')\n",
    "    print(f'id2label: {id2label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"get_grade\",\n",
      "    \"1\": \"get_passed_units\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"get_grade\": 0,\n",
      "    \"get_passed_units\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.29.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup the tokenizer and configuration\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "config = BertConfig.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH, **{\n",
    "        'label2id': label2id,\n",
    "        'id2label': id2label,\n",
    "    })\n",
    "\n",
    "if is_interactive():\n",
    "    print(config.to_json_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: \n",
      "چند واحد را با نمره مطلوب گذرانده‌ام؟\n",
      "get_passed_units\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(train))\n",
    "sample_text = train.iloc[idx]['text']\n",
    "sample_label = train.iloc[idx]['label']\n",
    "\n",
    "if is_interactive():\n",
    "    print(f'Sample: \\n{sample_text}\\n{sample_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Texts: چند واحد را با نمره مطلوب گذرانده‌ام؟\n",
      "   Tokens: چند واحد را با نمره مطلوب گذراندهام ؟\n",
      "Token IDs: [3102, 3926, 2803, 2799, 10105, 6964, 86469, 1350]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "\n",
    "if is_interactive():\n",
    "    print(f'   Texts: {sample_text}')\n",
    "    print(f'   Tokens: {tokenizer.convert_tokens_to_string(tokens)}')\n",
    "    print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "\n",
      "input_ids:\n",
      "tensor([[    2,  3102,  3926,  2803,  2799, 10105,  6964, 86469,  1350,     4,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n",
      "token_type_ids:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "attention_mask:\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "    sample_text,\n",
    "    max_length=32,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "    return_token_type_ids=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "if is_interactive():\n",
    "    print(f'Keys: {encoding.keys()}\\n')\n",
    "    for k in encoding.keys():\n",
    "        print(f'{k}:\\n{encoding[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentsDataset(torch.utils.data.Dataset):\n",
    "    \"\"\" Create a PyTorch dataset for Intents. \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, text, targets=None, label_list=None, max_len=128):\n",
    "        self.text = text\n",
    "        self.targets = targets\n",
    "        self.has_target = isinstance(targets, list) or isinstance(targets, np.ndarray)\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        \n",
    "        self.label_map = {label: i for i, label in enumerate(label_list)} if isinstance(label_list, list) else {}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.text[item])\n",
    "\n",
    "        if self.has_target:\n",
    "            target = self.label_map.get(str(self.targets[item]), str(self.targets[item]))\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        inputs = {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
    "        }\n",
    "\n",
    "        if self.has_target:\n",
    "            inputs['targets'] = torch.tensor(target, dtype=torch.long)\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "\n",
    "def create_data_loader(x, y, tokenizer, max_len, batch_size, label_list):\n",
    "    dataset = IntentsDataset(\n",
    "        text=x,\n",
    "        targets=y,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len, \n",
    "        label_list=label_list)\n",
    "    \n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(train['text'].to_numpy(), train['label'].to_numpy(), tokenizer, MAX_LEN, TRAIN_BATCH_SIZE, labels)\n",
    "valid_data_loader = create_data_loader(valid['text'].to_numpy(), valid['label'].to_numpy(), tokenizer, MAX_LEN, VALID_BATCH_SIZE, labels)\n",
    "test_data_loader = create_data_loader(test['text'].to_numpy(), None, tokenizer, MAX_LEN, TEST_BATCH_SIZE, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'input_ids', 'attention_mask', 'token_type_ids', 'targets'])\n",
      "['معدل من قابل قبوله؟', 'واحدهایی که به اتمام رسانده\\u200cای، چند تا بوده\\u200cاند؟', 'چند تا درس را با نمره A پاس کرده\\u200cام؟', 'معدلم چطور شده؟', 'واحدهایی که به دست آورده\\u200cام را به صورت تعداد بیان کنید.', 'چند تا درس را با نمره بالای ۱۶ گذرانده\\u200cام؟', 'چند واحد را با نمره مطلوب گذرانده\\u200cام؟', 'معدلم در این ترم چند شده به نظرت؟', 'معدلم چند تا شده؟', 'معدلم چنده؟', 'معدلم چقدر شده؟', 'واحدهایی که به صورت پاس شده ثبت شده\\u200cاند، چند تا هستند؟', 'معدل من در این ترم چی شده؟', 'چند واحد از مقاطع مختلف را گذرانده\\u200cام؟', 'معدل من با جزئیات چطور شده است؟', 'معدل من چقدر شده در این ترم؟']\n",
      "torch.Size([16, 128])\n",
      "tensor([    2, 21684,  2842,  3496,  5671,  2008,  1350,     4,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "torch.Size([16, 128])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([16, 128])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([16])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "sample_data = next(iter(train_data_loader))\n",
    "if is_interactive():\n",
    "    print(sample_data.keys())\n",
    "    print(sample_data['text'])\n",
    "    print(sample_data['input_ids'].shape)\n",
    "    print(sample_data['input_ids'][0, :])\n",
    "    print(sample_data['attention_mask'].shape)\n",
    "    print(sample_data['attention_mask'][0, :])\n",
    "    print(sample_data['token_type_ids'].shape)\n",
    "    print(sample_data['token_type_ids'][0, :])\n",
    "    print(sample_data['targets'].shape)\n",
    "    print(sample_data['targets'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'input_ids', 'attention_mask', 'token_type_ids'])\n"
     ]
    }
   ],
   "source": [
    "sample_test = next(iter(test_data_loader))\n",
    "if is_interactive():\n",
    "    print(sample_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentModel(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(IntentModel, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=False)\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "pt_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt_model <class '__main__.IntentModel'>\n"
     ]
    }
   ],
   "source": [
    "pt_model = IntentModel(config=config)\n",
    "pt_model = pt_model.to(device)\n",
    "\n",
    "state_dict = torch.load(f'{workspace_dir}/models/intent_classification.pt')\n",
    "\n",
    "if load_pretrained:\n",
    "    pt_model.load_state_dict(state_dict)\n",
    "    model_initialized = True\n",
    "\n",
    "if is_interactive():\n",
    "    print('pt_model', type(pt_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9870, -2.7887],\n",
      "        [-2.7005,  2.2860],\n",
      "        [-2.7710,  2.0322],\n",
      "        [ 2.9711, -2.7342],\n",
      "        [-2.1483,  1.7012]], grad_fn=<SliceBackward0>)\n",
      "tensor([0, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# sample data output\n",
    "\n",
    "sample_data_text = sample_data['text']\n",
    "sample_data_input_ids = sample_data['input_ids']\n",
    "sample_data_attention_mask = sample_data['attention_mask']\n",
    "sample_data_token_type_ids = sample_data['token_type_ids']\n",
    "sample_data_targets = sample_data['targets']\n",
    "\n",
    "# available for using in GPU\n",
    "sample_data_input_ids = sample_data_input_ids.to(device)\n",
    "sample_data_attention_mask = sample_data_attention_mask.to(device)\n",
    "sample_data_token_type_ids = sample_data_token_type_ids.to(device)\n",
    "sample_data_targets = sample_data_targets.to(device)\n",
    "\n",
    "\n",
    "# outputs = F.softmax(\n",
    "#     pt_model(sample_data_input_ids, sample_data_attention_mask, sample_data_token_type_ids), \n",
    "#     dim=1)\n",
    "\n",
    "outputs = pt_model(sample_data_input_ids, sample_data_attention_mask, sample_data_token_type_ids)\n",
    "_, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "\n",
    "if is_interactive():\n",
    "    print(outputs[:5, :])\n",
    "    print(preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracy(y_true, y_pred):\n",
    "    return (y_true == y_pred).mean()\n",
    "\n",
    "def acc_and_f1(y_true, y_pred, average='weighted'):\n",
    "    acc = simple_accuracy(y_true, y_pred)\n",
    "    f1 = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "def y_loss(y_true, y_pred, losses):\n",
    "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
    "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
    "    y = [y_true, y_pred]\n",
    "    loss = np.mean(losses)\n",
    "\n",
    "    return y, loss\n",
    "\n",
    "\n",
    "def eval_op(model, data_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for dl in tqdm(data_loader, total=len(data_loader), desc=\"Evaluation... \"):\n",
    "            \n",
    "            input_ids = dl['input_ids']\n",
    "            attention_mask = dl['attention_mask']\n",
    "            token_type_ids = dl['token_type_ids']\n",
    "            targets = dl['targets']\n",
    "\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "            \n",
    "            # convert output probabilities to predicted class\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            # accumulate all the losses\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(targets)\n",
    "    \n",
    "    eval_y, eval_loss = y_loss(y_true, y_pred, losses)\n",
    "    return eval_y, eval_loss\n",
    "\n",
    "\n",
    "def train_op(model, \n",
    "             data_loader, \n",
    "             loss_fn, \n",
    "             optimizer, \n",
    "             scheduler, \n",
    "             step=0, \n",
    "             print_every_step=100, \n",
    "             eval=False,\n",
    "             eval_cb=None,\n",
    "             eval_loss_min=np.Inf,\n",
    "             eval_data_loader=None, \n",
    "             clip=0.0):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for dl in tqdm(data_loader, total=len(data_loader), desc=\"Training... \"):\n",
    "        step += 1\n",
    "\n",
    "        input_ids = dl['input_ids']\n",
    "        attention_mask = dl['attention_mask']\n",
    "        token_type_ids = dl['token_type_ids']\n",
    "        targets = dl['targets']\n",
    "\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids)\n",
    "        \n",
    "        # convert output probabilities to predicted class\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # calculate the batch loss\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # accumulate all the losses\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        if clip > 0.0:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "\n",
    "        # perform optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "        # perform scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(targets)\n",
    "\n",
    "        if eval:\n",
    "            train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
    "            train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
    "\n",
    "            if step % print_every_step == 0:\n",
    "                eval_y, eval_loss = eval_op(model, eval_data_loader, loss_fn)\n",
    "                eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
    "\n",
    "                if hasattr(eval_cb, '__call__'):\n",
    "                    eval_loss_min = eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min)\n",
    "\n",
    "    train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
    "\n",
    "    return train_y, train_loss, step, eval_loss_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_pretrained:\n",
    "    optimizer = AdamW(pt_model.parameters(), lr=LEARNING_RATE, correct_bias=False, no_deprecation_warning=True)\n",
    "    total_steps = len(train_data_loader) * EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    step = 0\n",
    "    eval_loss_min = np.Inf\n",
    "    history = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "    def eval_callback(epoch, epochs, output_path):\n",
    "        def eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min):\n",
    "            statement = ''\n",
    "            statement += 'Epoch: {}/{}...'.format(epoch, epochs)\n",
    "            statement += 'Step: {}...'.format(step)\n",
    "            \n",
    "            statement += 'Train Loss: {:.6f}...'.format(train_loss)\n",
    "            statement += 'Train Acc: {:.3f}...'.format(train_score['acc'])\n",
    "\n",
    "            statement += 'Valid Loss: {:.6f}...'.format(eval_loss)\n",
    "            statement += 'Valid Acc: {:.3f}...'.format(eval_score['acc'])\n",
    "\n",
    "            print(statement)\n",
    "\n",
    "            if eval_loss <= eval_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                    eval_loss_min,\n",
    "                    eval_loss))\n",
    "                \n",
    "                torch.save(model.state_dict(), output_path)\n",
    "                eval_loss_min = eval_loss\n",
    "            \n",
    "            return eval_loss_min\n",
    "\n",
    "\n",
    "        return eval_cb\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(1, EPOCHS + 1), desc=\"Epochs... \"):\n",
    "        train_y, train_loss, step, eval_loss_min = train_op(\n",
    "            model=pt_model, \n",
    "            data_loader=train_data_loader, \n",
    "            loss_fn=loss_fn, \n",
    "            optimizer=optimizer, \n",
    "            scheduler=scheduler, \n",
    "            step=step, \n",
    "            print_every_step=EEVERY_EPOCH, \n",
    "            eval=True,\n",
    "            eval_cb=eval_callback(epoch, EPOCHS, OUTPUT_PATH),\n",
    "            eval_loss_min=eval_loss_min,\n",
    "            eval_data_loader=valid_data_loader, \n",
    "            clip=CLIP)\n",
    "        \n",
    "        train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
    "        \n",
    "        eval_y, eval_loss = eval_op(\n",
    "            model=pt_model, \n",
    "            data_loader=valid_data_loader, \n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
    "        \n",
    "        history['train_acc'].append(train_score['acc'])\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(eval_score['acc'])\n",
    "        history['val_loss'].append(eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, comments, tokenizer, max_len=128, batch_size=32):\n",
    "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size, None)\n",
    "    \n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for dl in tqdm(data_loader, position=0):\n",
    "            input_ids = dl['input_ids']\n",
    "            attention_mask = dl['attention_mask']\n",
    "            token_type_ids = dl['token_type_ids']\n",
    "\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            \n",
    "            # compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "            \n",
    "            # convert output probabilities to predicted class\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            prediction_probs.extend(F.softmax(outputs, dim=1))\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu().detach().numpy()\n",
    "\n",
    "    return predictions, prediction_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8465dc2e8234ca28867cf1084534bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,) (7, 2)\n"
     ]
    }
   ],
   "source": [
    "test_texts = test['text'].to_numpy()\n",
    "preds, probs = predict(pt_model, test_texts, tokenizer, max_len=128)\n",
    "\n",
    "if is_interactive():\n",
    "    print(preds.shape, probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 1.0\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       get_grade       1.00      1.00      1.00         4\n",
      "get_passed_units       1.00      1.00      1.00         3\n",
      "\n",
      "        accuracy                           1.00         7\n",
      "       macro avg       1.00      1.00      1.00         7\n",
      "    weighted avg       1.00      1.00      1.00         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = [labels.index(label) for label in test['label'].values], preds\n",
    "\n",
    "\n",
    "if is_interactive():\n",
    "    print(f'F1: {f1_score(y_test, y_pred, average=\"weighted\")}')\n",
    "    print()\n",
    "    print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4d54880540447fb15cefa4bfce89ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[[0.02587794 0.97412205]]\n"
     ]
    }
   ],
   "source": [
    "test_texts = np.array(['چند واحد پاس کردم'])\n",
    "preds, probs = predict(pt_model, test_texts, tokenizer, max_len=128)\n",
    "\n",
    "\n",
    "if is_interactive():\n",
    "    print(preds)\n",
    "    print(probs)\n",
    "# y_test, y_pred = [labels.index(label) for label in test['label'].values], preds\n",
    "\n",
    "# print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intention(text: str):\n",
    "    texts = np.array([text])\n",
    "    preds, probs = predict(pt_model, texts, tokenizer, max_len=128)\n",
    "\n",
    "    return preds, probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
